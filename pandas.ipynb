{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yc980802/.pyenv/versions/ptt/lib/python3.8/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from ckip_transformers.nlp import CkipNerChunker\n",
    "\n",
    "import os\n",
    "import json\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('info.pkl', 'rb') as f:\n",
    "    info_dicts = pk.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls, infos = info_dicts.keys(), info_dicts.values()\n",
    "title_list = [info['title'] for info in infos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98871/98871 [00:04<00:00, 22480.05it/s]\n",
      "Inference: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 155/155 [02:12<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "ner_driver = CkipNerChunker(level=3, device=0)\n",
    "ner = ner_driver(title_list, batch_size=1024, use_delim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for url, sentence_ner in zip(urls, ner):\n",
    "    # sentence_ner有兩個以上的專有名詞\n",
    "    for entity in sentence_ner:\n",
    "        if entity.ner == 'GPE':\n",
    "            data.append([url, entity.word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['url', 'country'])\n",
    "inference_country = list(df.country.unique())\n",
    "famous_country = pd.read_csv('country.csv').iloc[:, 0]\n",
    "\n",
    "for fctry in famous_country:\n",
    "    for ctry in inference_country:\n",
    "        if fctry in ctry:\n",
    "            df['country'].replace(ctry, fctry, inplace=True)\n",
    "            \n",
    "df = df[df['country'].isin(famous_country)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsondict = df.groupby('country')['url'].apply(list).to_dict()\n",
    "needed_info = ['title']\n",
    "for country, url_list in jsondict.items():\n",
    "    content_list = []\n",
    "    for url in url_list:\n",
    "        info = {k: info_dicts[url][k] for k in needed_info}\n",
    "        info['url'] = url\n",
    "        content_list.append(info)\n",
    "    jsondict[country] = content_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('content.json', 'w') as jsonfile:\n",
    "    json.dump(jsondict, jsonfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptt",
   "language": "python",
   "name": "ptt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
